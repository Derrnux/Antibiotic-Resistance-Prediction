from itertools import product

class SEQTokenizer_Kmers:
    """Custom tokenizer for DNA sequences with k-mers, truncation, and padding."""
    def __init__(self, k, max_length=512, pad_token_id=0):
        self.k = k
        self.max_length = max_length
        self.pad_token_id = pad_token_id

        # Create vocabulary of all possible k-mers
        self.vocab = [''.join(kmer) for kmer in product('ATCG', repeat=k)]
        self.token_to_id = {token: i for i, token in enumerate(self.vocab)}

    def encode(self, sequence):
        """
        Tokenizes the input sequence into k-mers and maps them to token IDs.
        Pads and truncates the tokenized output to max_length.

        Args:
            sequence (str): Input DNA sequence.

        Returns:
            List[int]: Tokenized sequence with padding and truncation applied.
        """
        # Generate k-mers and convert to token IDs
        kmers = [sequence[i:i+self.k] for i in range(len(sequence) - self.k + 1)]
        token_ids = [self.token_to_id[kmer] for kmer in kmers if kmer in self.token_to_id]

        # Truncate to max_length
        token_ids = token_ids[:self.max_length]

        # Pad if the sequence is shorter than max_length
        if len(token_ids) < self.max_length:
            token_ids += [self.pad_token_id] * (self.max_length - len(token_ids))

        return token_ids

tokenizer = SEQTokenizer_Kmers(k=6)
