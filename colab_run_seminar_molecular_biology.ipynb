{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This was run using the following split:\n",
    "- Test: 7/7\n",
    "- Val: 7/7\n",
    "- Train: 26/96  <- more training than in \"tryout_models\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_seed = 44\n",
    "best_model = None\n",
    "best_model_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F71tpVhATZf9",
    "outputId": "b9b94078-43ba-4c68-f436-2d710faa9669"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "directory = \"seminar-dlmb-2024-winter-public\"\n",
    "\n",
    "if os.path.exists(directory) and os.listdir(directory):\n",
    "    print(f\"Directory {directory} exists and is non-empty.\")\n",
    "else:\n",
    "    print(f\"Directory {directory} does not exist or is empty.\")\n",
    "    !!git clone https://github.com/hzi-bifo/seminar-dlmb-2024-winter-public.git\n",
    "\n",
    "directory = \"Antibiotic-Resistance-Prediction\"\n",
    "\n",
    "if os.path.exists(directory) and os.listdir(directory):\n",
    "    print(f\"Directory {directory} exists and is non-empty.\")\n",
    "else:\n",
    "    print(f\"Directory {directory} does not exist or is empty.\")\n",
    "    !!git clone https://github.com/Derrnux/Antibiotic-Resistance-Prediction.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QVSdzzgUXBMB",
    "outputId": "5270774f-1405-4ce4-b3d7-5c7368c0bbc6"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "source_dir = \"Antibiotic-Resistance-Prediction\"\n",
    "\n",
    "dest_dir = \".\"\n",
    "\n",
    "for filename in os.listdir(source_dir):\n",
    "    source_path = os.path.join(source_dir, filename)\n",
    "    dest_path = os.path.join(dest_dir, filename)\n",
    "\n",
    "    shutil.move(source_path, dest_path)\n",
    "\n",
    "print(f\"Files moved from '{source_dir}' to '{dest_dir}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ki_Gkj9LXgzu",
    "outputId": "9d1e88ce-bd9a-49b7-e284-2eef72ce3de9"
   },
   "outputs": [],
   "source": [
    "!pip install biopython seaborn\n",
    "%pip install biopython\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BNCMaEVctnv",
    "outputId": "1f610d2d-d2e3-45a6-b6ae-69385f6d6bca"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JuZFemYUT3Th"
   },
   "outputs": [],
   "source": [
    "from transformer_manager import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y7v45fJoWzoh",
    "outputId": "ff418314-ee2c-4c2b-ec27-f4a19111ae15"
   },
   "outputs": [],
   "source": [
    "custom_model = Transformer(k_mers_type = 1, attention_layers = 3, batch_size = 32,  balancing_method = 'class_weights', embed_dim = 128, dim_feedforward = 2048, seed = global_seed)\n",
    "custom_model.train(epochs = 50, learning_rate = 1e-4)\n",
    "model_score = custom_model.evaluate()\n",
    "if (model_score > best_model_score):\n",
    "    best_model = custom_model\n",
    "    best_model_score = model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEjRuMZi3NLo",
    "outputId": "aa1b5328-d8f5-496e-8453-0e82b1d0db5c"
   },
   "outputs": [],
   "source": [
    "custom_model = Transformer(k_mers_type = 2, attention_layers = 4, batch_size = 32,  balancing_method = 'class_weights', embed_dim = 128, dim_feedforward = 2048, seed = global_seed)\n",
    "custom_model.train(epochs = 500, learning_rate = 1e-4)\n",
    "model_score = custom_model.evaluate()\n",
    "if (model_score > best_model_score):\n",
    "    best_model = custom_model\n",
    "    best_model_score = model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CeriB2MwiKx1",
    "outputId": "5f30ac99-0eda-416c-8c54-1ea037d3e99d"
   },
   "outputs": [],
   "source": [
    "custom_model = Transformer(k_mers_type = 3, attention_layers = 4, batch_size = 32,  balancing_method = 'class_weights', embed_dim = 128, dim_feedforward = 2048, seed = global_seed)\n",
    "custom_model.train(epochs = 200, learning_rate = 1e-4)\n",
    "model_score = custom_model.evaluate()\n",
    "if (model_score > best_model_score):\n",
    "    best_model = custom_model\n",
    "    best_model_score = model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2VZmXuaflJ7J",
    "outputId": "dd28b831-7b88-4cd2-ac15-a6e2a58d9556"
   },
   "outputs": [],
   "source": [
    "custom_model = Transformer(k_mers_type = 4, attention_layers = 6, batch_size = 32,  balancing_method = 'class_weights', embed_dim = 256, dim_feedforward = 2048, seed = global_seed)\n",
    "custom_model.train(epochs = 400, learning_rate = 1e-5)\n",
    "model_score = custom_model.evaluate()\n",
    "if (model_score > best_model_score):\n",
    "    best_model = custom_model\n",
    "    best_model_score = model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = Transformer(k_mers_type = 6, attention_layers = 6, batch_size = 32,  balancing_method = 'class_weights', embed_dim = 256, dim_feedforward = 2048, seed = global_seed)\n",
    "custom_model.train(epochs = 400, learning_rate = 1e-5)\n",
    "model_score = custom_model.evaluate()\n",
    "if (model_score > best_model_score):\n",
    "    best_model = custom_model\n",
    "    best_model_score = model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = Transformer(k_mers_type = 6, attention_layers = 8, batch_size = 32,  balancing_method = 'class_weights', embed_dim = 256, dim_feedforward = 2048, seed = global_seed)\n",
    "custom_model.train(epochs = 400, learning_rate = 1e-5)\n",
    "model_score = custom_model.evaluate()\n",
    "if (model_score > best_model_score):\n",
    "    best_model = custom_model\n",
    "    best_model_score = model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = Transformer(k_mers_type = 8, attention_layers = 10, batch_size = 32,  balancing_method = 'class_weights', embed_dim = 256, dim_feedforward = 2048, seed = global_seed)\n",
    "custom_model.train(epochs = 400, learning_rate = 1e-5)\n",
    "model_score = custom_model.evaluate()\n",
    "if (model_score > best_model_score):\n",
    "    best_model = custom_model\n",
    "    best_model_score = model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = Transformer(k_mers_type = 10, attention_layers = 12, batch_size = 32,  balancing_method = 'class_weights', embed_dim = 256, dim_feedforward = 2048, seed = global_seed)\n",
    "custom_model.train(epochs = 500, learning_rate = 1e-6)\n",
    "model_score = custom_model.evaluate()\n",
    "if (model_score > best_model_score):\n",
    "    best_model = custom_model\n",
    "    best_model_score = model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = Transformer(k_mers_type = 10, attention_layers = 12, batch_size = 32,  balancing_method = 'class_weights', embed_dim = 512, dim_feedforward = 2048, seed = global_seed)\n",
    "custom_model.train(epochs = 500, learning_rate = 1e-6)\n",
    "model_score = custom_model.evaluate()\n",
    "if (model_score > best_model_score):\n",
    "    best_model = custom_model\n",
    "    best_model_score = model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = Transformer(k_mers_type = 10, attention_layers = 16, batch_size = 32,  balancing_method = 'class_weights', embed_dim = 512, dim_feedforward = 2048, seed = global_seed)\n",
    "custom_model.train(epochs = 500, learning_rate = 1e-6)\n",
    "model_score = custom_model.evaluate()\n",
    "if (model_score > best_model_score):\n",
    "    best_model = custom_model\n",
    "    best_model_score = model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.test()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
